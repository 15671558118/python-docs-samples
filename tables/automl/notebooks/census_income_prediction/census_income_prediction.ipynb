{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of automltables_v1beta1_quickstart.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "m26YhtBMvVWA"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting started with AutoML Tables\n",
        "\n",
        "To use this Colab notebook, copy it to your own Google Drive and open it with [Colaboratory](https://colab.research.google.com/) (or Colab). To run a cell hold the Shift key and press the Enter key (or Return key). Colab automatically displays the return value of the last line in each cell. Refer to [this page](https://colab.sandbox.google.com/notebooks/welcome.ipynb) for more information on Colab.\n",
        "\n",
        "You can run a Colab notebook on a hosted runtime in the Cloud. The hosted VM times out after 90 minutes of inactivity and you will lose all the data stored in the memory including your authentication data. If your session gets disconnected (for example, because you closed your laptop) for less than the 90 minute inactivity timeout limit, press 'RECONNECT' on the top right corner of your notebook and resume the session. After Colab timeout, you'll need to\n",
        "\n",
        "1.   Re-run the initialization and authentication.\n",
        "2.   Continue from where you left off. You may need to copy-paste the value of some variables such as the `dataset_name` from the printed output of the previous cells.\n",
        "\n",
        "Alternatively you can connect your Colab notebook to a [local runtime](https://research.google.com/colaboratory/local-runtimes.html).\n",
        "\n",
        "**Note to Googlers:** `pip` is not enabled for the internal (or corp) version of Colab. Use the [external version of Colab](https://colab.research.google.com/).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "b--5FDDwCG9C"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Project set up\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AZs0ICgy4jkQ"
      },
      "cell_type": "markdown",
      "source": [
        "Follow the [AutoML Tables documentation](https://cloud.google.com/automl-tables/docs/) to\n",
        "* Create a Google Cloud Platform (GCP) project.\n",
        "* Enable billing.\n",
        "* Apply to whitelist your project.\n",
        "* Enable AutoML API.\n",
        "* Enable AutoML Tables API.\n",
        "* Create a service account, grant required permissions, and download the service account private key.\n",
        "\n",
        "You also need to upload your data into Google Cloud Storage (GCS) or BigQuery. For example, to use GCS as your data source\n",
        "* Create a GCS bucket.\n",
        "* Upload the training and batch prediction files.\n",
        "\n",
        "\n",
        "**Warning:** Private keys must be kept secret. If you expose your private key it is recommended to revoke it immediately from the Google Cloud Console."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xZECt1oL429r"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rstRPH9SyZj_"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Initialize and authenticate\n",
        "This section runs intialization and authentication. It creates an authenticated session which is required for running any of the following sections."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BR0POq2UzE7e"
      },
      "cell_type": "markdown",
      "source": [
        "### Install the client library\n",
        "Run the following cell. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "43aXKjDRt_qZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "604afaa9-540c-494a-edf2-f87b0d6889d6"
      },
      "cell_type": "code",
      "source": [
        "#@title Install AutoML Tables client library { vertical-output: true }\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from google.colab import files\n",
        "import tarfile\n",
        "\n",
        "!pip install google-cloud-automl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-automl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a7/2d90dd55e99edb2a8b1ccee83ba92ef750bd823117737ed6976163b6f85f/google_cloud_automl-0.2.0-py2.py3-none-any.whl (139kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-automl) (1.8.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (1.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (1.5.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (1.11.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (40.8.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (2.18.4)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (3.7.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (2018.9)\n",
            "Requirement already satisfied: grpcio>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (3.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (0.2.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (2019.3.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-automl) (0.4.5)\n",
            "Installing collected packages: google-cloud-automl\n",
            "Successfully installed google-cloud-automl-0.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eVFsPPEociwF"
      },
      "cell_type": "markdown",
      "source": [
        "### Authenticate using service account key\n",
        "Run the following cell. Click on the 'Choose Files' button and select the service account private key file. If your Service Account key file or folder is hidden, you can reveal it in a Mac by pressing the <b>Command + Shift + .</b> combo."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u-kCqysAuaJk",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7d13ba3a-6411-4d7a-e29d-a8daf79919f4"
      },
      "cell_type": "code",
      "source": [
        "#@title Authenticate and create a client. { vertical-output: true }\n",
        "\n",
        "from google.cloud import automl_v1beta1\n",
        "\n",
        "# Upload service account key\n",
        "keyfile_upload = files.upload()\n",
        "keyfile_name = list(keyfile_upload.keys())[0]\n",
        "# Authenticate and create an AutoML client.\n",
        "client = automl_v1beta1.AutoMlClient.from_service_account_file(keyfile_name)\n",
        "# Authenticate and create a prediction service client.\n",
        "prediction_client = automl_v1beta1.PredictionServiceClient.from_service_account_file(keyfile_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bca2ae9c-a68e-44b3-8e5a-603b18f332ec\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bca2ae9c-a68e-44b3-8e5a-603b18f332ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2b8758eeb86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Upload service account key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkeyfile_upload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkeyfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyfile_upload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Authenticate and create an AutoML client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml_v1beta1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoMlClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_service_account_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s3F2xbEJdDvN"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0uX4aJYUiXh5"
      },
      "cell_type": "markdown",
      "source": [
        "Enter your GCP project ID."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6R4h5HF1Dtds",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title GCP project ID and location\n",
        "\n",
        "project_id = 'my-project-trial5' #@param {type:'string'}\n",
        "location = 'us-central1'\n",
        "location_path = client.location_path(project_id, location)\n",
        "location_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rUlBcZ3OfWcJ"
      },
      "cell_type": "markdown",
      "source": [
        "To test whether your project set up and authentication steps were successful, run the following cell to list your datasets."
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "sf32nKXIqYje",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title List datasets. { vertical-output: true }\n",
        "\n",
        "list_datasets_response = client.list_datasets(location_path)\n",
        "datasets = {\n",
        "    dataset.display_name: dataset.name for dataset in list_datasets_response}\n",
        "datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9uE8MvMkOPd"
      },
      "cell_type": "markdown",
      "source": [
        "You can also print the list of your models by running the following cell."
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "j4-bYRSWj7xk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title List models. { vertical-output: true }\n",
        "\n",
        "list_models_response = client.list_models(location_path)\n",
        "models = {model.display_name: model.name for model in list_models_response}\n",
        "models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qozQWMnOu48y"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ODt86YuVDZzm"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Import training data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XwjZc9Q62Fm5"
      },
      "cell_type": "markdown",
      "source": [
        "### Create dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_JfZFGSceyE_"
      },
      "cell_type": "markdown",
      "source": [
        "Select a dataset display name and pass your table source information to create a new dataset."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z_JErW3cw-0J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Create dataset { vertical-output: true, output-height: 200 }\n",
        "\n",
        "dataset_display_name = 'test_deployment' #@param {type: 'string'}\n",
        "\n",
        "create_dataset_response = client.create_dataset(\n",
        "    location_path,\n",
        "    {'display_name': dataset_display_name, 'tables_dataset_metadata': {}})\n",
        "dataset_name = create_dataset_response.name\n",
        "create_dataset_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "35YZ9dy34VqJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Import data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3c0o15gVREAw"
      },
      "cell_type": "markdown",
      "source": [
        "You can import your data to AutoML Tables from GCS or BigQuery. For this tutorial, you can use the [census_income dataset](https://storage.googleapis.com/automl-tables-v1beta1/census_income.csv) \n",
        "as your training data. You can create a GCS bucket and upload the  data intofa your bucket. The URI for your file is `gs://BUCKET_NAME/FOLDER_NAME1/FOLDER_NAME2/.../FILE_NAME`. Alternatively you can create a BigQuery table and upload the data into the table. The URI for your table is `bq://PROJECT_ID.DATASET_ID.TABLE_ID`.\n",
        "\n",
        "Importing data may take a few minutes or hours depending on the size of your data. If your Colab times out, run the following command to retrieve your dataset. Replace `dataset_name` with its actual value obtained in the preceding cells.\n",
        "\n",
        "    dataset = client.get_dataset(dataset_name)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UIWlq3NTYhOl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ... if data source is GCS { vertical-output: true }\n",
        "\n",
        "dataset_gcs_input_uris = ['gs://automl-tables-v1beta1/census_income.csv',] #@param\n",
        "# Define input configuration.\n",
        "input_config = {\n",
        "    'gcs_source': {\n",
        "        'input_uris': dataset_gcs_input_uris\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bB_GdeqCJW5i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ... if data source is BigQuery { vertical-output: true }\n",
        "\n",
        "dataset_bq_input_uri = 'bq://my-project-trial5.census_income.income_census' #@param {type: 'string'}\n",
        "# Define input configuration.\n",
        "input_config = {\n",
        "    'bigquery_source': {\n",
        "        'input_uri': dataset_bq_input_uri\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNVYfpoXJsNB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " #@title Import data { vertical-output: true }\n",
        "\n",
        "import_data_response = client.import_data(dataset_name, input_config)\n",
        "print('Dataset import operation: {}'.format(import_data_response.operation))\n",
        "# Wait until import is done.\n",
        "import_data_result = import_data_response.result()\n",
        "import_data_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QdxBI4s44ZRI"
      },
      "cell_type": "markdown",
      "source": [
        "### Review the specs"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RC0PWKqH4jwr"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following command to see table specs such as row count."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v2Vzq_gwXxo-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Table schema { vertical-output: true }\n",
        "\n",
        "import google.cloud.automl_v1beta1.proto.data_types_pb2 as data_types\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List table specs\n",
        "list_table_specs_response = client.list_table_specs(dataset_name)\n",
        "table_specs = [s for s in list_table_specs_response]\n",
        "# List column specs\n",
        "table_spec_name = table_specs[0].name\n",
        "list_column_specs_response = client.list_column_specs(table_spec_name)\n",
        "column_specs = {s.display_name: s for s in list_column_specs_response}\n",
        "# Table schema pie chart.\n",
        "type_counts = {}\n",
        "for column_spec in column_specs.values():\n",
        "  type_name = data_types.TypeCode.Name(column_spec.data_type.type_code)\n",
        "  type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
        "\n",
        "plt.pie(x=type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%')\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vcJP7xoq4yAJ"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following command to see column specs such inferred schema."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FNykW_YOYt6d"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kNRVJqVOL8h3"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Update dataset: assign a label column and enable nullable columns"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-57gehId9PQ5"
      },
      "cell_type": "markdown",
      "source": [
        "AutoML Tables automatically detects your data column type. For example, for the ([census_income](https://storage.googleapis.com/automl-tables-v1beta1/census_income.csv)) it detects `income` to be categorical (as it is just either over or under 50k) and `age` to be numerical. Depending on the type of your label column, AutoML Tables chooses to run a classification or regression model. If your label column contains only numerical values, but they represent categories, change your label column type to categorical by updating your schema."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iRqdQ7Xiq04x"
      },
      "cell_type": "markdown",
      "source": [
        "### Update a column: set to nullable"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OCEUIPKegWrf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Update dataset { vertical-output: true }\n",
        "\n",
        "update_column_spec_dict = {\n",
        "    'name': column_specs['income'].name,\n",
        "    'data_type': {\n",
        "        'type_code': 'CATEGORY',\n",
        "        'nullable': False\n",
        "    }\n",
        "}\n",
        "update_column_response = client.update_column_spec(update_column_spec_dict)\n",
        "update_column_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GUqKi3tkqrgW"
      },
      "cell_type": "markdown",
      "source": [
        "**Tip:** You can use `'type_code': 'CATEGORY'` in the preceding `update_column_spec_dict` to convert the column data type from `FLOAT64` `to `CATEGORY`."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nDMH_chybe4w"
      },
      "cell_type": "markdown",
      "source": [
        "### Update dataset: assign a label"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hVIruWg0u33t",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Update dataset { vertical-output: true }\n",
        "\n",
        "label_column_name = 'income' #@param {type: 'string'}\n",
        "label_column_spec = column_specs[label_column_name]\n",
        "label_column_id = label_column_spec.name.rsplit('/', 1)[-1]\n",
        "print('Label column ID: {}'.format(label_column_id))\n",
        "# Define the values of the fields to be updated.\n",
        "update_dataset_dict = {\n",
        "    'name': dataset_name,\n",
        "    'tables_dataset_metadata': {\n",
        "        'target_column_spec_id': label_column_id\n",
        "    }\n",
        "}\n",
        "update_dataset_response = client.update_dataset(update_dataset_dict)\n",
        "update_dataset_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "z23NITLrcxmi"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FcKgvj1-Tbgj"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Creating a model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Pnlk8vdQlO_k"
      },
      "cell_type": "markdown",
      "source": [
        "### Train a model\n",
        "Specify the duration of the training. For example, `'train_budget_milli_node_hours': 1000` runs the training for one hour. If your Colab times out, use `client.list_models(location_path)` to check whether your model has been created. Then use model name to continue to the next steps. Run the following command to retrieve your model. Replace `model_name` with its actual value.\n",
        "\n",
        "    model = client.get_model(model_name)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "11izNd6Fu37N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Create model { vertical-output: true }\n",
        "\n",
        "model_display_name = 'census_income_model' #@param {type:'string'}\n",
        "\n",
        "model_dict = {\n",
        "    'display_name': model_display_name,\n",
        "    'dataset_id': dataset_name.rsplit('/', 1)[-1],\n",
        "    'tables_model_metadata': {'train_budget_milli_node_hours': 1000}\n",
        "}\n",
        "create_model_response = client.create_model(location_path, model_dict)\n",
        "print('Dataset import operation: {}'.format(create_model_response.operation))\n",
        "# Wait until model training is done.\n",
        "create_model_result = create_model_response.result()\n",
        "model_name = create_model_result.name\n",
        "create_model_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1wS1is9IY5nK"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LMYmHSiCE8om"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Make a prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G2WVbMFll96k"
      },
      "cell_type": "markdown",
      "source": [
        "### There are two different prediction modes: online and batch. The following cells show you how to make an online prediction. "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZAGi8Co-SU-b"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following cell, and then choose the desired test values for your online prediction."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yt-KXEEQu3-U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Make an online prediction: set the categorical variables{ vertical-output: true }\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "\n",
        "workclass_ids = ['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked']\n",
        "education_ids = ['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool']\n",
        "marital_status_ids = ['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse']\n",
        "occupation_ids = ['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces']\n",
        "relationship_ids = ['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried']\n",
        "race_ids = ['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black']\n",
        "sex_ids = ['Female', 'Male']\n",
        "native_country_ids = ['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal', 'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands']\n",
        "workclass = widgets.Dropdown(options=workclass_ids, value=workclass_ids[0],\n",
        "                           description='workclass:')\n",
        "\n",
        "education = widgets.Dropdown(options=education_ids, value=education_ids[0],\n",
        "                           description='education:', width='500px')\n",
        "\n",
        "marital_status = widgets.Dropdown(options=marital_status_ids, value=marital_status_ids[0],\n",
        "                           description='marital status:', width='500px')\n",
        "\n",
        "occupation = widgets.Dropdown(options=occupation_ids, value=occupation_ids[0],\n",
        "                           description='occupation:', width='500px')\n",
        "\n",
        "relationship = widgets.Dropdown(options=relationship_ids, value=relationship_ids[0],\n",
        "                           description='relationship:', width='500px')\n",
        "\n",
        "race = widgets.Dropdown(options=race_ids, value=race_ids[0],\n",
        "                           description='race:', width='500px')\n",
        "\n",
        "sex = widgets.Dropdown(options=sex_ids, value=sex_ids[0],\n",
        "                           description='sex:', width='500px')\n",
        "\n",
        "native_country = widgets.Dropdown(options=native_country_ids, value=native_country_ids[0],\n",
        "                           description='native_country:', width='500px')\n",
        "\n",
        "display(workclass)\n",
        "display(education)\n",
        "display(marital_status)\n",
        "display(occupation)\n",
        "display(relationship)\n",
        "display(race)\n",
        "display(sex)\n",
        "display(native_country)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xGVGwgwXSZe_"
      },
      "cell_type": "markdown",
      "source": [
        "Adjust the slides on the right to the desired test values for your online prediction."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bDzd5GYQSdpa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Make an online prediction: set the numeric variables{ vertical-output: true }\n",
        "\n",
        "age = 34 #@param {type:'slider', min:1, max:100, step:1}\n",
        "capital_gain = 40000 #@param {type:'slider', min:0, max:100000, step:10000}\n",
        "capital_loss = 3.8 #@param {type:'slider', min:0, max:4000, step:0.1}\n",
        "fnlwgt = 150000 #@param {type:'slider', min:0, max:1000000, step:50000}\n",
        "education_num = 9 #@param {type:'slider', min:1, max:16, step:1}\n",
        "hours_per_week = 40 #@param {type:'slider', min:1, max:100, step:1}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n0lFAIkISf4K"
      },
      "cell_type": "markdown",
      "source": [
        "<font color=red> IMPORTANT: Deploy the model, then wait until the model FINISHES deployment.\n",
        "Check the [UI](https://console.cloud.google.com/automl-tables?_ga=2.255483016.-1079099924.1550856636) and navigate to the predict tab of your model, and then to the online prediction portion, to see when it finishes online deployment before running the prediction cell.</span>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kRoHFbVnSk05",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "response = client.deploy_model(model_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0tymBrhLSnDX"
      },
      "cell_type": "markdown",
      "source": [
        "Run the prediction, only after the model finishes deployment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Kc4SKLLPSoKz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_client.predict(model_name, payload)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "O9CRdIfrS1nb"
      },
      "cell_type": "markdown",
      "source": [
        "Undeploy the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DWa1idtOS0GE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "response2 = client.undeploy_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TarOq84-GXch"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Batch prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Soy5OB8Wbp_R"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "39bIGjIlau5a"
      },
      "cell_type": "markdown",
      "source": [
        "Your data source for batch prediction can be GCS or BigQuery. For this tutorial, you can use [census_income_batch_prediction_input.csv](https://storage.googleapis.com/automl-tables-v1beta1/census_income_batch_prediction_input.csv) as input source. Create a GCS bucket and upload the file into your bucket. Some of the lines in the batch prediction input file are intentionally left missing some values. The AutoML Tables logs the errors in the `errors.csv` file.\n",
        "Also, enter the UI and create the bucket into which you will load your predictions. The bucket's default name here is automl-tables-pred.\n",
        "\n",
        "**NOTE:** The client library has a bug. If the following cell returns a `TypeError: Could not convert Any to BatchPredictResult` error, ignore it. The batch prediction output file(s) will be updated to the GCS bucket that you set in the preceding cells."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gkF3bH0qu4DU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Start batch prediction { vertical-output: true, output-height: 200 }\n",
        "\n",
        "batch_predict_gcs_input_uris = ['gs://automl-tables-v1beta1/census_income_batch_prediction_input.csv',] #@param\n",
        "batch_predict_gcs_output_uri_prefix = 'gs://automl-tables-pred1' #@param {type:'string'}\n",
        "#gs://automl-tables-pred\n",
        "# Define input source.\n",
        "batch_prediction_input_source = {\n",
        "  'gcs_source': {\n",
        "    'input_uris': batch_predict_gcs_input_uris\n",
        "  }\n",
        "}\n",
        "# Define output target.\n",
        "batch_prediction_output_target = {\n",
        "    'gcs_destination': {\n",
        "      'output_uri_prefix': batch_predict_gcs_output_uri_prefix\n",
        "    }\n",
        "}\n",
        "batch_predict_response = prediction_client.batch_predict(\n",
        "    model_name, batch_prediction_input_source, batch_prediction_output_target)\n",
        "print('Batch prediction operation: {}'.format(batch_predict_response.operation))\n",
        "# Wait until batch prediction is done.\n",
        "batch_predict_result = batch_predict_response.result()\n",
        "batch_predict_response.metadata"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}